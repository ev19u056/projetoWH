
 
 **Model_Ver_1** : Neuron-Layers: 62 64 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:300 ; Epochs: 100 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_1** : Neuron-Layers: 62 64 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:300 ; Epochs: 100 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_1** : Neuron-Layers: 59 64 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:300 ; Epochs: 100 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_3** : Neuron-Layers: 59 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 10 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_3** : Neuron-Layers: 53 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 10 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_3** : Neuron-Layers: 53 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 10 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_3** : Neuron-Layers: 53 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 20 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_4** : Neuron-Layers: 53 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 20 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_5** : Neuron-Layers: 53 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 10 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_6** : Neuron-Layers: 53 54 53 53 53 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 10 ; Step size: 0.001 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_3** : Neuron-Layers: 53 64 62 62 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 10 ; Step size: 0.0001 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_3** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 1e-05 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 