
 
 **Model_Ver_1** : Neuron-Layers: 62 64 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:300 ; Epochs: 100 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_1** : Neuron-Layers: 62 64 62 1 ; Activation: relu ; Output: Sigmoid ; Batch size:300 ; Epochs: 100 ; Step size: 0.01 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 