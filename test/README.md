
 **Model_Ver_3** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 250 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_4** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 

 
 **Model_Ver_5** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_6** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 250 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_6** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_7** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_8** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_9** : Neuron-Layers: 53 54 60 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size:3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Weight Initializer: glorot_uniform   ; fraction: 0.1; PCA implemented
 
 
 **Model_Ver_10** : Neuron-Layers: 53 54 60 40 30 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_11** : Neuron-Layers: 53 54 60 40 30 20 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_12** : Neuron-Layers: 53 54 60 30 15 10 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 200 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_13** : Neuron-Layers: 53 54 60 30 15 10 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 300 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.0 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_14** : Neuron-Layers: 53 54 60 30 15 10 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 200 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.549666696331 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_15** : Neuron-Layers: 53 54 60 30 10 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 120 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.583472537327 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_16** : Neuron-Layers: 53 54 60 15 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 100 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.439469690196 ; Weight Initializer: glorot_uniform   
 
 
 **Model_Ver_17** : Neuron-Layers: 53 54 60 30 20 10 1 ; Activation: relu ; Output: Sigmoid ; Batch size: 3000 ; Epochs: 120 ; Step size: 0.003 ; Optimizer: Adam ; Regulizer: 0 ; Max FOM : 0.585438985289 ; Weight Initializer: glorot_uniform   
 
